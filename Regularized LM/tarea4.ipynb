{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Construyendo un proyecto de aprendizaje de máquina**\n",
    "\n",
    "*Códigos referencia del libro Hands-On Machine Learning with Scikit-Learn and Tensor Flow 2017 (Cap 2) -- Aurélien Géron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapas principales en un sistema de aprendizaje de máquina\n",
    "\n",
    "1. Observar el problema (ayuda interdisciplinar)\n",
    "2. Obtener los datos\n",
    "3. Análisis exploratorio incial (visualizar los datos y estadística descriptiva básica)\n",
    "4. Preparar los datos para los algoritmos de aprendizaje de máquina (evaluación, preproceso, caracterización, aprendizaje)\n",
    "5. Seleccionar un modelo y entrenar\n",
    "6. Sintonizar el modelo escogido\n",
    "7. Presentar la solución\n",
    "8. Lanzar la solución, monitorear y mantener el sistema de aprendizaje de máquina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problema a resolver\n",
    "\n",
    "*Objetivo: predecir precios medios en distritos de California-USA.*\n",
    "\n",
    "*Insumos: Características de los distritos*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicio códigos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparar modulos principales, funciones inline, paths para guardar archivos y figuras:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"end_to_end_project\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"imagesAM\", CHAPTER_ID)\n",
    "HOUSING_PATH = \"datasets/housing/\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtener los datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = load_housing_data()\n",
    "housing.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis exploratorio básico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "housing.hist(bins=50, figsize=(20,15))\n",
    "save_fig(\"attribute_histogram_plots\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparar datos (validación y análisis exploratorio por visualización)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"median_income\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preproceso variable median_income -> continua a categórica**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                               labels=[1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "housing[\"income_cat\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"income_cat\"].hist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Muestreo estratificado de datos: asegurar mismas proporciones en las particiones de datos con base a característica de interés**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"].values):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set[\"income_cat\"].value_counts() / len(strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"income_cat\"].value_counts() / len(housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparar errores en particiones con y sin estratificación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def income_cat_proportions(data):\n",
    "    return data[\"income_cat\"].value_counts() / len(data)\n",
    "\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n",
    "\n",
    "compare_props = pd.DataFrame({\n",
    "    \"Overall\": income_cat_proportions(housing),\n",
    "    \"Stratified\": income_cat_proportions(strat_test_set),\n",
    "    \"Random\": income_cat_proportions(test_set),\n",
    "}).sort_index()\n",
    "compare_props[\"Rand. %error\"] = 100 * compare_props[\"Random\"] / compare_props[\"Overall\"] - 100\n",
    "compare_props[\"Strat. %error\"] = 100 * compare_props[\"Stratified\"] / compare_props[\"Overall\"] - 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_ in (strat_train_set, strat_test_set): #remove rows or columns\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis exploratorio y visualización sobre datos muestreados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\")\n",
    "save_fig(\"bad_visualization_plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.2)\n",
    "save_fig(\"better_visualization_plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The argument `sharex=False` fixes a display bug (the x-axis values and legend were not displayed). This is a temporary fix (see: https://github.com/pandas-dev/pandas/issues/10611). Thanks to Wilmer Arellano for pointing it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n",
    "    s=housing[\"population\"]/100, label=\"population\", figsize=(10,7),\n",
    "    c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n",
    "    sharex=False)\n",
    "plt.legend()\n",
    "save_fig(\"housing_prices_scatterplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "california_img=mpimg.imread(PROJECT_ROOT_DIR + '/imagesAM/end_to_end_project/california.png')\n",
    "ax = housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", figsize=(10,7),\n",
    "                       s=housing['population']/100, label=\"Population\",\n",
    "                       c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"),\n",
    "                       colorbar=False, alpha=0.4,\n",
    "                      )\n",
    "plt.imshow(california_img, extent=[-124.55, -113.80, 32.45, 42.05], alpha=0.5,\n",
    "           cmap=plt.get_cmap(\"jet\"))\n",
    "plt.ylabel(\"Latitude\", fontsize=14)\n",
    "plt.xlabel(\"Longitude\", fontsize=14)\n",
    "\n",
    "prices = housing[\"median_house_value\"]\n",
    "tick_values = np.linspace(prices.min(), prices.max(), 11)\n",
    "cbar = plt.colorbar()\n",
    "cbar.ax.set_yticklabels([\"$%dk\"%(round(v/1000)) for v in tick_values], fontsize=14)\n",
    "cbar.set_label('Median House Value', fontsize=16)\n",
    "\n",
    "plt.legend(fontsize=16)\n",
    "save_fig(\"california_housing_prices_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identificación de correlaciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = housing.corr()\n",
    "corr_matrix.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(corr_matrix,xticklabels=corr_matrix.columns.values,yticklabels=corr_matrix.columns.values)\n",
    "save_fig(\"corr_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas.tools.plotting import scatter_matrix # For older versions of Pandas\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n",
    "              \"housing_median_age\"]\n",
    "scatter_matrix(housing[attributes], figsize=(12, 8))\n",
    "save_fig(\"scatter_matrix_plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\",\n",
    "             alpha=0.1)\n",
    "plt.axis([0, 16, 0, 550000])\n",
    "save_fig(\"income_vs_house_value_scatterplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generar nuevas características intuitivas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
    "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = housing.corr()\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"rooms_per_household\", y=\"median_house_value\",\n",
    "             alpha=0.2)\n",
    "plt.axis([0, 5, 0, 520000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparar los datos para los algoritmos de aprendizaje de máquina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.drop(\"median_house_value\", axis=1) # drop labels for training set\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_incomplete_rows = housing[housing.isnull().any(axis=1)].head()\n",
    "sample_incomplete_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opciones básicas para lidiar con datos perdidos\n",
    "\n",
    "1. Quitar filas (instancias con característica perdida)\n",
    "2. Quitar columnas (se elimina la característica completa si presenta datos perdidos)\n",
    "3. Se estiman los valores perdidos mediante mediana, promedio, moda, o estimaciones por vecindario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_incomplete_rows.dropna(subset=[\"total_bedrooms\"])    # option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_incomplete_rows.drop(\"total_bedrooms\", axis=1)       # option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = housing[\"total_bedrooms\"].median()\n",
    "sample_incomplete_rows[\"total_bedrooms\"].fillna(median, inplace=True) # option 3\n",
    "sample_incomplete_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clase Imputer de scikit-learn contiene este preproceso para datos perdidos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from sklearn.impute import SimpleImputer # Scikit-Learn 0.20+\n",
    "except ImportError:\n",
    "    from sklearn.preprocessing import Imputer as SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se deben remover las variables nominales para aplicar la opción por mediana:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_num = housing.drop('ocean_proximity', axis=1)\n",
    "# alternatively: housing_num = housing.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.fit(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.statistics_ #valores obtenidos en preproceso imputer por atributo numérico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dichos valores son las mismas medianas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_num.median().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicar el preproceso (transformación) según lo entrenado con imputer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imputer.transform(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_tr = pd.DataFrame(X, columns=housing_num.columns,\n",
    "                          index = list(housing.index.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_tr.loc[sample_incomplete_rows.index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_tr = pd.DataFrame(X, columns=housing_num.columns)\n",
    "housing_tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cómo trabajar con variables nominales (categóricas)? (ej: 'ocean_proximity')\n",
    "\n",
    "1. Etiquetar (codificar) los textos. Problemas: la noción de cercanía pierde sentido\n",
    "2. One-hot-encoding, una nueva característica binaria se genera por cada categoría de la variable de interés. Problema: el número de características crece considerablemente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cat = housing[['ocean_proximity']]\n",
    "housing_cat.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from sklearn.preprocessing import OrdinalEncoder\n",
    "except ImportError:\n",
    "    from future_encoders import OrdinalEncoder # Scikit-Learn < 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
    "housing_cat_encoded[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from sklearn.preprocessing import OrdinalEncoder # just to raise an ImportError if Scikit-Learn < 0.20\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "except ImportError:\n",
    "    from future_encoders import OneHotEncoder # Scikit-Learn < 0.20\n",
    "\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "housing_cat_1hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por defecto, la clase `OneHotEncoder` retorna un arreglo ralo (sparse), se puede usar la función `toarray()` para trabajar con arreglos completos (full)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cat_1hot.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se puede fijar la opción  `sparse=False` en `OneHotEncoder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoder = OneHotEncoder(sparse=False)\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "housing_cat_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a custom transformer to add extra attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "rooms_ix, bedrooms_ix, population_ix, household_ix = [\n",
    "    list(housing.columns).index(col)\n",
    "    for col in (\"total_rooms\", \"total_bedrooms\", \"population\", \"households\")]\n",
    "\n",
    "\n",
    "def add_extra_features(X, add_bedrooms_per_room=True):\n",
    "    rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
    "    population_per_household = X[:, population_ix] / X[:, household_ix]\n",
    "    if add_bedrooms_per_room:\n",
    "        bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "        return np.c_[X, rooms_per_household, population_per_household,\n",
    "                     bedrooms_per_room]\n",
    "    else:\n",
    "        return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "attr_adder = FunctionTransformer(add_extra_features, validate=False,\n",
    "                                 kw_args={\"add_bedrooms_per_room\": False})\n",
    "housing_extra_attribs = attr_adder.fit_transform(housing.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_extra_attribs = pd.DataFrame(\n",
    "    housing_extra_attribs,\n",
    "    columns=list(housing.columns)+[\"rooms_per_household\", \"population_per_household\"])\n",
    "housing_extra_attribs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esquema general (pipeline) de preproceso para atributos numéricos\n",
    "\n",
    "1. Lidiar con datos perdidos -> SimpleImputer\n",
    "2. Añadir nuevos atributos desde conocimiento a priori (equipo interdisciplinar) -> FunctionTransformer\n",
    "3. Escalado de atributos (min max ; estandarización - zscore). Min-max sensible a atípicos  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import stats\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('attribs_adder', FunctionTransformer(add_extra_features, validate=False)),\n",
    "        ('std_scaler', StandardScaler()), #MinMaxScaler StandardScaler\n",
    "    ])\n",
    "\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
    "housing_labels=stats.zscore(housing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un esquema general, incluyendo atributos numéricos y categóricos se puede generar con la clase `ColumnTransformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "except ImportError:\n",
    "    from future_encoders import ColumnTransformer # Scikit-Learn < 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs), #OneHotEncoder or OrdinalEncoder()\n",
    "    ])\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleccionar un modelo y entrenar sobre los datos preparados,Sintonizar parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión lineal\n",
    "\n",
    "La regresión lineal es una técnica de análisis predictivo básica que utiliza datos históricos para predecir una variable de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scoreslin_reg = cross_val_score(lin_reg, housing_prepared, housing_labels,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=5) #scikitlearn trabaja con función util (mayor mejor) no función de costo (menor mejor)\n",
    "tree_rmse_scores_lin_reg = np.sqrt(-scoreslin_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(tree_rmse_scores_lin_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Curvas de aprendizaje \"\n",
    "plt.figure()\n",
    "plt.title(title)\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Score\")\n",
    "\n",
    "#Validación cruzada para pintar las curvas de entrenamiento y validación e incertidumbre   \n",
    "train_sizes_lin_reg, train_scores_lin_reg, test_scores_lin_reg= \\\n",
    "    learning_curve(lin_reg, housing_prepared, housing_labels,\n",
    "                   scoring=\"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "train_scores_mean_lin_reg= abs(np.mean(train_scores_lin_reg, axis=1))\n",
    "train_scores_std_lin_reg = abs(np.std(train_scores_lin_reg, axis=1))\n",
    "test_scores_mean_lin_reg =abs( np.mean(test_scores_lin_reg, axis=1))\n",
    "test_scores_std_lin_reg =abs( np.std(test_scores_lin_reg, axis=1))\n",
    "\n",
    "\n",
    "plt.grid()\n",
    "plt.fill_between(train_sizes_lin_reg, train_scores_mean_lin_reg - train_scores_std_lin_reg,\n",
    "                 train_scores_mean_lin_reg + train_scores_std_lin_reg, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "plt.fill_between(train_sizes_lin_reg, test_scores_mean_lin_reg - test_scores_std_lin_reg,\n",
    "                 test_scores_mean_lin_reg + test_scores_std_lin_reg, alpha=0.1, color=\"g\")\n",
    "\n",
    "plt.plot(train_sizes_lin_reg, train_scores_mean_lin_reg, 'o-', color=\"r\",\n",
    "         label=\"Training score\")\n",
    "plt.plot(train_sizes_lin_reg, test_scores_mean_lin_reg, 'o-', color=\"g\",\n",
    "         label=\"Cross-validation score\")\n",
    "\n",
    "plt.legend(loc=\"best\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión de Ridge \n",
    "\n",
    "Regresión de Ridge La regresión lineal regular tiene la forma de: J (theta) = MSE (theta) La regresión de Ridge aplica un término de regularización proporcional al cuadrado de la norma l2 de los pesos de las características (sin incluir la intersección). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "param_grid_ridgeReg={ \"alpha\": [0.1,1,60,200, 1000]}\n",
    "\n",
    "ridgeReg = Ridge(alpha=10)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search_ridgeReg = GridSearchCV(ridgeReg, param_grid_ridgeReg, cv=5,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "\n",
    "grid_search_ridgeReg.fit(housing_prepared, housing_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres_ridgeReg = grid_search_ridgeReg.cv_results_    \n",
    "testscores_mean_ridgeReg =abs(cvres_ridgeReg[\"mean_test_score\"])\n",
    "testscores_sd_ridgeReg = abs(cvres_ridgeReg['std_test_score'])\n",
    "\n",
    "trainscores_mean_ridgeReg =abs(cvres_ridgeReg['mean_train_score'])\n",
    "trainscores_sd_ridgeReg = abs(cvres_ridgeReg[ 'std_train_score'])\n",
    "\n",
    "\n",
    "\n",
    "X_axis_ridgeReg = np.array(cvres_ridgeReg['param_alpha'].data, dtype=float)\n",
    "plt.fill_between(X_axis_ridgeReg, testscores_mean_ridgeReg - testscores_sd_ridgeReg,\n",
    "                        testscores_mean_ridgeReg + testscores_sd_ridgeReg,alpha=0.1,color=\"r\")    \n",
    "plt.plot(X_axis_ridgeReg, testscores_mean_ridgeReg, 'o-', color=\"r\",\n",
    "         label=\"Training score\")\n",
    "\n",
    "plt.fill_between(X_axis_ridgeReg, trainscores_mean_ridgeReg - trainscores_sd_ridgeReg,\n",
    "                 trainscores_mean_ridgeReg + trainscores_sd_ridgeReg, alpha=0.1, color=\"g\")\n",
    "\n",
    "plt.plot(X_axis_ridgeReg, trainscores_mean_ridgeReg, 'o-', color=\"g\",\n",
    "         label=\"Cross-validation score\")\n",
    "\n",
    "X_best_params_ridgeReg=grid_search_ridgeReg.best_params_\n",
    "X_alpha_ridgeReg = cvres_ridgeReg['param_alpha'].data\n",
    "plt.plot([X_best_params_ridgeReg.get(\"alpha\"), ] * 2, [0.3, abs(testscores_mean_ridgeReg[np.where(X_alpha_ridgeReg == X_best_params_ridgeReg.get(\"alpha\"))])],\n",
    "         linestyle='-.', color='k', marker='x', markeredgewidth=2, ms=8)\n",
    "\n",
    "plt.annotate(\"%0.2f\" % abs(testscores_mean_ridgeReg[np.where(X_alpha_ridgeReg == X_best_params_ridgeReg.get(\"alpha\") )]),\n",
    "             (X_best_params_ridgeReg.get(\"alpha\") , abs(testscores_mean_ridgeReg[np.where(X_alpha_ridgeReg == X_best_params_ridgeReg.get(\"alpha\") )]+ 0.005)))\n",
    "\n",
    "plt.grid()\n",
    "plt.legend(loc=\"best\") \n",
    "title = \"Curvas de aprendizaje \"\n",
    "plt.title(title)\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los mejores hyperparámetros encontrados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_ridgeReg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_ridgeReg.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mean_score, params in zip(cvres_ridgeReg[\"mean_test_score\"], cvres_ridgeReg[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression\n",
    "La ventaja de la regresión de Lazo sobre la rigida se encuentra en la forma de diamante del contorno de la penalización de la norma l1, lo que hace que algunas de las tetas se eliminen (se establezcan en 0) rápidamente. Esto significa que la regresión Lasso puede realizar la selección automática de características, cuando la regresión rigida no puede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "param_grid_Lasso={ \"alpha\": [0.001,0.009,0.02,0.3,2,4]}\n",
    "ridLasso = Lasso(alpha=2)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search_ridLasso = GridSearchCV(ridLasso, param_grid_Lasso, cv=5,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search_ridLasso.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "cvres_ridLasso = grid_search_ridLasso.cv_results_    \n",
    "testscores_mean_ridLasso =abs(cvres_ridLasso[\"mean_test_score\"])\n",
    "testscores_sd_ridLasso = abs(cvres_ridLasso['std_test_score'])\n",
    "\n",
    "trainscores_mean_ridLasso =abs(cvres_ridLasso['mean_train_score'])\n",
    "trainscores_sd_ridLasso = abs(cvres_ridLasso[ 'std_train_score'])\n",
    "\n",
    "X_axis_ridLasso = np.array(cvres_ridLasso['param_alpha'].data, dtype=float)\n",
    "\n",
    "plt.fill_between(X_axis_ridLasso, testscores_mean_ridLasso - testscores_sd_ridLasso,\n",
    "                        testscores_mean_ridLasso + testscores_sd_ridLasso,alpha=0.1,color=\"r\")   \n",
    "\n",
    "plt.plot(X_axis_ridLasso, testscores_mean_ridLasso, 'o-', color=\"r\",\n",
    "         label=\"Training score\")\n",
    "\n",
    "plt.fill_between(X_axis_ridLasso, trainscores_mean_ridLasso - trainscores_sd_ridLasso,\n",
    "                 trainscores_mean_ridLasso + trainscores_sd_ridLasso, alpha=0.1, color=\"g\")\n",
    "\n",
    "plt.plot(X_axis_ridLasso, trainscores_mean_ridLasso, 'o-', color=\"g\",\n",
    "         label=\"Cross-validation score\")\n",
    "\n",
    "X_best_params_ridLasso=grid_search_ridLasso.best_params_\n",
    "\n",
    "X_alpha_ridLasso = cvres_ridLasso['param_alpha'].data\n",
    "\n",
    "plt.plot([X_best_params_ridLasso.get(\"alpha\"), ] * 2, [0, abs(testscores_mean_ridLasso[np.where(X_alpha_ridLasso == X_best_params_ridLasso.get(\"alpha\"))])],\n",
    "         linestyle='-.', color='k', marker='x', markeredgewidth=2, ms=8)\n",
    "\n",
    "plt.annotate(\"%0.2f\" % abs(testscores_mean_ridLasso[np.where(X_alpha_ridLasso == X_best_params_ridLasso.get(\"alpha\"))]),\n",
    "             (X_best_params_ridLasso.get(\"alpha\"), abs(testscores_mean_ridLasso[np.where(X_alpha_ridLasso == X_best_params_ridLasso.get(\"alpha\"))]+ 0.005)))\n",
    "\n",
    "plt.legend(loc=\"best\") \n",
    "\n",
    "\n",
    "plt.grid()\n",
    "plt.legend(loc=\"best\") \n",
    "title = \"Curvas de aprendizaje \"\n",
    "plt.title(title)\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Score\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los mejores hyperparámetros encontrados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_ridLasso.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_ridLasso.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mean_score, params in zip(cvres_ridLasso[\"mean_test_score\"], cvres_ridLasso[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Net\n",
    "La red elástica está en algún lugar entre la regresión de la cresta y la regresión del lazo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "alpha = np.array([0.0001,0.1,10])\n",
    "l1_ratio = np.array([2,20,50])\n",
    "\n",
    "param_grid_ElasticNet= [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {\"alpha\": alpha,\"l1_ratio\": l1_ratio}\n",
    "  ]\n",
    "\n",
    "\n",
    "ridElastic = ElasticNet(alpha = 0.1, l1_ratio =0.1)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search_ridElastic = GridSearchCV(ridElastic, param_grid_ElasticNet, cv=5,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search_ridElastic.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres_ridElastic = grid_search_ridElastic.cv_results_ \n",
    "\n",
    "X_best_params_ridElastic=grid_search_ridElastic.best_params_\n",
    "testscores_mean_ridElastic = abs(cvres_ridElastic[\"mean_test_score\"])\n",
    "testscores_mean_ridElastic = np.array(testscores_mean_ridElastic).reshape(len(l1_ratio),len(alpha))\n",
    "\n",
    "testscores_sd_ridElastic  =  abs(cvres_ridElastic['std_test_score'])\n",
    "testscores_sd_ridElastic = np.array(testscores_sd_ridElastic).reshape(len(l1_ratio),len(alpha))\n",
    "\n",
    "# Plot Grid search scores\n",
    "_, ax = plt.subplots(1,1)\n",
    "\n",
    "# Param1 is the X-axis, Param 2 is represented as a different curve (color line)\"l1_ratio\" \"alpha\"\n",
    "for idx, val in enumerate(alpha):\n",
    "    ax.plot(l1_ratio, testscores_mean_ridElastic[idx,:], '-o', label= 'alpha' + ': ' + str(val)) \n",
    "\n",
    "ax.plot([X_best_params_ridElastic.get(\"l1_ratio\"), ] * 2, [0, abs(testscores_mean_ridElastic[np.where(alpha == X_best_params_ridElastic.get(\"alpha\")),np.where(l1_ratio == X_best_params_ridElastic.get(\"l1_ratio\"))])],\n",
    "        linestyle='-.', color='k', marker='x', markeredgewidth=2, ms=8)  \n",
    "ax.grid()\n",
    "ax.set_title(\"Grid Search Scores\", fontsize=20, fontweight='bold')\n",
    "ax.set_xlabel('alpha', fontsize=16)\n",
    "ax.set_ylabel('CV Average Score', fontsize=16)\n",
    "ax.legend(loc=\"best\", fontsize=15)\n",
    "ax.annotate(\"%0.4f\" % abs(testscores_mean_ridElastic[np.where(alpha == X_best_params_ridElastic.get(\"alpha\")),np.where(l1_ratio == X_best_params_ridElastic.get(\"l1_ratio\"))]),\n",
    "             (X_best_params_ridElastic.get(\"l1_ratio\"), abs(testscores_mean_ridElastic[np.where(alpha == X_best_params_ridElastic.get(\"alpha\")),np.where(l1_ratio == X_best_params_ridElastic.get(\"l1_ratio\"))] + 0.005)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_ridElastic.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_ridElastic.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mean_score, params in zip(cvres_ridElastic[\"mean_test_score\"],cvres_ridElastic[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KernelRidge rbf\n",
    "\n",
    "combina Kernel ridge regression(mínimos cuadrados lineales con la regularización de la norma l2) con el truco del kernel. Así aprende una función lineal en el espacio inducido por el kernel respectivo y los datos. Para los núcleos no lineales, esto corresponde a una función no lineal en el espacio original.\n",
    "\n",
    "Nota: al tener tantos dato el proceso podría tardar un tiempo considerable si no se paraleliza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "gamma = np.array([0.00001,0.0001,0.01,0.1])\n",
    "param_grid_kernel = [ {\"gamma\": gamma}]\n",
    "\n",
    "grid_search_KernelRidge= GridSearchCV(KernelRidge(kernel='rbf', gamma=0.1),param_grid_kernel, cv=5,\n",
    "                                         scoring='neg_mean_squared_error', return_train_score=True)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search_KernelRidge.fit(housing_prepared[:6500,:], housing_labels[:6500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres_KernelRidge = grid_search_KernelRidge.cv_results_     \n",
    "testscores_mean_KernelRidge =abs(cvres_KernelRidge[\"mean_test_score\"])\n",
    "testscores_sd_KernelRidge = abs(cvres_KernelRidge['std_test_score'])\n",
    "\n",
    "trainscores_mean_KernelRidge =abs(cvres_KernelRidge['mean_train_score'])\n",
    "trainscores_sd_KernelRidge = abs(cvres_KernelRidge[ 'std_train_score'])\n",
    "\n",
    "\n",
    "\n",
    "X_axis_KernelRidge = np.array(cvres_KernelRidge['param_gamma'].data, dtype=float)\n",
    "plt.fill_between(X_axis_KernelRidge, testscores_mean_KernelRidge - testscores_sd_KernelRidge,\n",
    "                        testscores_mean_KernelRidge + testscores_sd_KernelRidge,alpha=0.1,color=\"r\")    \n",
    "plt.plot(X_axis_KernelRidge, testscores_mean_KernelRidge, 'o-', color=\"r\",\n",
    "         label=\"Training score\")\n",
    "\n",
    "plt.fill_between(X_axis_KernelRidge, trainscores_mean_KernelRidge - trainscores_sd_KernelRidge,\n",
    "                 trainscores_mean_KernelRidge + trainscores_sd_KernelRidge, alpha=0.1, color=\"g\")\n",
    "\n",
    "plt.plot(X_axis_KernelRidge, trainscores_mean_KernelRidge, 'o-', color=\"g\",\n",
    "         label=\"Cross-validation score\")\n",
    "\n",
    "X_best_params_KernelRidge=grid_search_KernelRidge.best_params_\n",
    "X_alpha_KernelRidge = cvres_KernelRidge['param_gamma'].data\n",
    "\n",
    "plt.plot([X_best_params_KernelRidge.get(\"gamma\"), ] * 2, [0, abs(testscores_mean_KernelRidge[np.where(X_alpha_KernelRidge == X_best_params_KernelRidge.get(\"gamma\"))])],\n",
    "         linestyle='-.', color='k', marker='x', markeredgewidth=2, ms=8)\n",
    "\n",
    "plt.annotate(\"%0.2f\" % abs(testscores_mean_KernelRidge[np.where(X_alpha_KernelRidge == X_best_params_KernelRidge.get(\"gamma\"))]),\n",
    "             (X_best_params_KernelRidge.get(\"gamma\"), abs(testscores_mean_KernelRidge[np.where(X_alpha_KernelRidge == X_best_params_KernelRidge.get(\"gamma\"))]+ 0.005)))\n",
    "\n",
    "plt.legend(loc=\"best\") \n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_KernelRidge.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_KernelRidge.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mean_score, params in zip(cvres_KernelRidge[\"mean_test_score\"],cvres_KernelRidge[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Ridge linear\n",
    "\n",
    "combina Kernel ridge regression(mínimos cuadrados lineales con la regularización de la norma l2) con el truco del kernel. Así aprende una función lineal en el espacio inducido por el kernel respectivo y los datos. Para los núcleos no lineales, esto corresponde a una función no lineal en el espacio original.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "ridKernelRidge_l =KernelRidge(kernel='linear')\n",
    "ridKernelRidge_l.fit(housing_prepared[:8500,:],housing_labels[:8500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KernelRidge_l = cross_val_score(ridKernelRidge_l , housing_prepared[:8500,:],housing_labels[:8500],\n",
    "                         scoring=\"neg_mean_squared_error\", cv=5) #scikitlearn trabaja con función util (mayor mejor) no función de costo (menor mejor)\n",
    "tree_rmse_scores_KernelRidge_l = np.sqrt(-KernelRidge_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(tree_rmse_scores_KernelRidge_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Curvas de aprendizaje \"\n",
    "plt.figure()\n",
    "plt.title(title)\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Score\")\n",
    "\n",
    "    \n",
    "train_sizes_KernelRidge_l, train_scores_KernelRidge_l, test_scores_KernelRidge_l = \\\n",
    "    learning_curve(ridKernelRidge_l, housing_prepared[:8500,:],housing_labels[:8500],\n",
    "                   scoring=\"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "train_scores_mean_KernelRidge_l = abs(np.mean(train_scores_KernelRidge_l, axis=1))\n",
    "train_scores_std_KernelRidge_l = abs(np.std(train_scores_KernelRidge_l, axis=1))\n",
    "test_scores_mean_KernelRidge_l = abs(np.mean(test_scores_KernelRidge_l, axis=1))\n",
    "test_scores_std_KernelRidge_l = abs(np.std(test_scores_KernelRidge_l, axis=1))\n",
    "plt.grid()\n",
    "plt.fill_between(train_sizes_KernelRidge_l, train_scores_mean_KernelRidge_l - train_scores_std_KernelRidge_l,\n",
    "                 train_scores_mean_KernelRidge_l + train_scores_std_KernelRidge_l, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "plt.fill_between(train_sizes_KernelRidge_l, test_scores_mean_KernelRidge_l - test_scores_std_KernelRidge_l,\n",
    "                 test_scores_mean_KernelRidge_l + test_scores_std_KernelRidge_l, alpha=0.1, color=\"g\")\n",
    "\n",
    "plt.plot(train_sizes_KernelRidge_l, train_scores_mean_KernelRidge_l, 'o-', color=\"r\",\n",
    "         label=\"Training score\")\n",
    "plt.plot(train_sizes_KernelRidge_l, test_scores_mean_KernelRidge_l, 'o-', color=\"g\",\n",
    "         label=\"Cross-validation score\")\n",
    "\n",
    "plt.legend(loc=\"best\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Ridge Regression\n",
    "\n",
    "estima un modelo probabilístico del problema de regresión como se describe anteriormente. El previo para el coeficiente. w Es dado por un gaussiano esférico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "ridBayesianRidge =BayesianRidge(compute_score=True)\n",
    "ridBayesianRidge.fit(housing_prepared,housing_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BayesianRidge = cross_val_score(ridBayesianRidge ,housing_prepared,housing_labels,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=5) #scikitlearn trabaja con función util (mayor mejor) no función de costo (menor mejor)\n",
    "tree_rmse_scores_BayesianRidge = np.sqrt(-BayesianRidge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(tree_rmse_scores_BayesianRidge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Curvas de aprendizaje \"\n",
    "plt.figure()\n",
    "plt.title(title)\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Score\")\n",
    "    \n",
    "train_sizes_BayesianRidge, train_scores_BayesianRidge, test_scores_BayesianRidge = \\\n",
    "    learning_curve(ridBayesianRidge, housing_prepared,housing_labels,\n",
    "                   scoring=\"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "train_scores_mean_BayesianRidge =abs( np.mean(train_scores_BayesianRidge, axis=1))\n",
    "train_scores_std_BayesianRidge = abs(np.std(train_scores_BayesianRidge, axis=1))\n",
    "test_scores_mean_BayesianRidge = abs(np.mean(test_scores_BayesianRidge, axis=1))\n",
    "test_scores_std_BayesianRidge = abs(np.std(test_scores_BayesianRidge, axis=1))\n",
    "plt.grid()\n",
    "plt.fill_between(train_sizes_BayesianRidge, train_scores_mean_BayesianRidge - train_scores_std_BayesianRidge,\n",
    "                 train_scores_mean_BayesianRidge + train_scores_std_BayesianRidge, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "plt.fill_between(train_sizes_BayesianRidge, test_scores_mean_BayesianRidge - test_scores_std_BayesianRidge,\n",
    "                 test_scores_mean_BayesianRidge + test_scores_std_BayesianRidge, alpha=0.1, color=\"g\")\n",
    "\n",
    "plt.plot(train_sizes_BayesianRidge, train_scores_mean_BayesianRidge, 'o-', color=\"r\",\n",
    "         label=\"Training score\")\n",
    "plt.plot(train_sizes_BayesianRidge, test_scores_mean_BayesianRidge, 'o-', color=\"g\",\n",
    "         label=\"Cross-validation score\")\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.title(\"Marginal log-likelihood\")\n",
    "plt.plot(ridBayesianRidge.scores_, color='navy', linewidth=2)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xlabel(\"Iterations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Relevance Determination Regression (ARD)\n",
    "\n",
    "Ajuste los pesos de un modelo de regresión, utilizando un ARD anterior. Se asume que los pesos del modelo de regresión están en distribuciones gaussianas. También estimar los parámetros lambda (precisiones de las distribuciones de los pesos) y alfa (precisión de la distribución del ruido). La estimación se realiza mediante un procedimiento iterativo (Maximización de la evidencia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ARDRegression\n",
    "\n",
    "threshold_lambda = np.array([0.001,10,12,15])\n",
    "param_grid_ARD = [ {\"threshold_lambda\": threshold_lambda}]\n",
    "\n",
    "grid_search_ARD= GridSearchCV(ARDRegression(threshold_lambda=1e5),param_grid_ARD, cv=5,\n",
    "                                         scoring='neg_mean_squared_error', return_train_score=True)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search_ARD.fit(housing_prepared[:8500,:],housing_labels[:8500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres_ARD = grid_search_ARD.cv_results_    \n",
    "testscores_mean_ARD =abs(cvres_ARD[\"mean_test_score\"])\n",
    "testscores_sd_ARD = abs(cvres_ARD['std_test_score'])\n",
    "\n",
    "trainscores_mean_ARD =abs(cvres_ARD['mean_train_score'])\n",
    "trainscores_sd_ARD = abs(cvres_ARD[ 'std_train_score'])\n",
    "\n",
    "X_axis_ARD= np.array(cvres_ARD['param_threshold_lambda'].data, dtype=float)\n",
    "plt.fill_between(X_axis_ARD, testscores_mean_ARD- testscores_sd_ARD,\n",
    "                        testscores_mean_ARD + testscores_sd_ARD,alpha=0.1,color=\"r\")    \n",
    "\n",
    "plt.plot(X_axis_ARD, testscores_mean_ARD, 'o-', color=\"r\",label=\"Training score\")\n",
    "\n",
    "plt.fill_between(X_axis_ARD, trainscores_mean_ARD - trainscores_sd_ARD,\n",
    "                 trainscores_mean_ARD + trainscores_sd_ARD, alpha=0.1, color=\"g\")\n",
    "\n",
    "plt.plot(X_axis_ARD, trainscores_mean_ARD, 'o-', color=\"g\",\n",
    "         label=\"Cross-validation score\")\n",
    "\n",
    "X_best_params_ARD=grid_search_ARD.best_params_\n",
    "X_alpha_ARD = cvres_ARD['param_threshold_lambda'].data\n",
    "\n",
    "plt.plot([X_best_params_ARD.get('threshold_lambda'), ] * 2, [0, abs(testscores_mean_ARD[np.where(X_alpha_ARD == X_best_params_ARD.get('threshold_lambda'))])],\n",
    "         linestyle='-.', color='k', marker='x', markeredgewidth=2, ms=8)\n",
    "\n",
    "plt.annotate(\"%0.2f\" % abs(testscores_mean_ARD[np.where(X_alpha_ARD== X_best_params_ARD.get('threshold_lambda'))]),\n",
    "             (X_best_params_ARD.get('threshold_lambda'), abs(testscores_mean_ARD[np.where(X_alpha_ARD == X_best_params_ARD.get('threshold_lambda'))]+ 0.005)))\n",
    "\n",
    "plt.legend(loc=\"best\") \n",
    "plt.grid()\n",
    "plt.legend(loc=\"best\") \n",
    "title = \"Curvas de aprendizaje \"\n",
    "plt.title(title)\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_ARD.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mean_score, params in zip(cvres_ARD[\"mean_test_score\"],cvres_ARD[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleccionar un modelo Sintonizado con los mejores parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#linear regression\n",
    "test_rmse_scores_lin_reg = np.sqrt(test_scores_mean_lin_reg )\n",
    "#Regresión de Ridge\n",
    "test_score_ridgeReg=np.array([abs(cvres_ridgeReg['split0_test_score']),abs(cvres_ridgeReg['split1_test_score']),\n",
    "                              abs(cvres_ridgeReg['split2_test_score']),abs(cvres_ridgeReg['split3_test_score']),\n",
    "                              abs(cvres_ridgeReg['split4_test_score'])])\n",
    "params_optimo_ridgeReg=np.where(X_alpha_ridgeReg == X_best_params_ridgeReg.get(\"alpha\"))\n",
    "test_rmse_scores_ridgeReg=np.sqrt(test_score_ridgeReg[0:,np.int(params_optimo_ridgeReg[-1])])\n",
    "\n",
    "#Regresión de Lasso\n",
    "test_score_Lasso=np.array([abs(cvres_ridLasso['split0_test_score']),abs(cvres_ridLasso['split1_test_score']),\n",
    "                           abs(cvres_ridLasso['split2_test_score']),abs(cvres_ridLasso['split3_test_score']),\n",
    "                           abs(cvres_ridLasso['split4_test_score'])])\n",
    "params_optimo_Lassog=np.where(X_alpha_ridLasso == X_best_params_ridLasso.get(\"alpha\"))\n",
    "test_rmse_scores_Lassog=np.sqrt(test_score_Lasso[0:,np.int(params_optimo_Lassog[-1])])\n",
    "\n",
    "#Regresión de Elastic\n",
    "test_score_Elastic=np.array([abs(cvres_ridElastic['split0_test_score']),abs(cvres_ridElastic['split1_test_score']),\n",
    "                             abs(cvres_ridElastic['split2_test_score']),abs(cvres_ridElastic['split3_test_score']),\n",
    "                             abs(cvres_ridElastic['split4_test_score'])])\n",
    "\n",
    "\n",
    "\n",
    "params_optimo_Elastic=np.where(np.array(cvres_ridElastic['params'])==grid_search_ridElastic.best_params_)\n",
    "test_rmse_scores_Elastic=np.sqrt(test_score_Elastic[0:,np.int(params_optimo_Elastic[-1])])\n",
    "\n",
    "#KernelRidge rbf\n",
    "test_score_KernelRidg=np.array([abs(cvres_KernelRidge['split0_test_score']),abs(cvres_KernelRidge['split1_test_score']),\n",
    "                                abs(cvres_KernelRidge['split2_test_score']),abs(cvres_KernelRidge['split3_test_score']),\n",
    "                                abs(cvres_KernelRidge['split4_test_score'])])\n",
    "params_optimo_KernelRidg=np.where(X_alpha_KernelRidge == X_best_params_KernelRidge.get(\"gamma\"))\n",
    "test_rmse_scores_KernelRidg=np.sqrt(test_score_KernelRidg[0:,np.int(params_optimo_KernelRidg[-1])])\n",
    "\n",
    "#Kernel Ridge linear\n",
    "test_rmse_scores_KernelRidge_l = np.sqrt(test_scores_mean_KernelRidge_l )\n",
    "\n",
    "#Bayesian Ridge Regression\n",
    "test_rmse_BayesianRidge=np.sqrt(test_scores_mean_BayesianRidge)\n",
    "\n",
    "\n",
    "#Automatic Relevance Determination Regression (ARD)\n",
    "\n",
    "test_score_ARD=np.array([abs(cvres_ARD['split0_test_score']),abs(cvres_ARD['split1_test_score']),\n",
    "                         abs(cvres_ARD['split2_test_score']),abs(cvres_ARD['split3_test_score']),\n",
    "                         abs(cvres_ARD['split4_test_score'])])\n",
    "\n",
    "params_optimo_ARD=np.where(X_alpha_ARD == X_best_params_ARD.get('threshold_lambda'))\n",
    "test_rmse_scores_ARD=np.sqrt(test_score_ARD[0:,np.int(params_optimo_ARD[-1])])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que convierte los datos en el factor de euros\n",
    "def modelos_name(name):\n",
    "    # Convert M in value column to millions\n",
    "    if name == 1.0:\n",
    "        return 'LinearRegression'\n",
    "    if name == 2.0:\n",
    "        return 'RegresRidge'\n",
    "    if name == 3.0:\n",
    "        return 'RegresLasso'\n",
    "    if name == 4.0:\n",
    "        return 'Elastic'\n",
    "    if name == 5.0:\n",
    "        return 'KernelRidge'\n",
    "    if name == 6.0:\n",
    "        return 'KernelRidgel'\n",
    "    if name == 7.0:\n",
    "        return 'Bayesian'\n",
    "    if name == 8.0:\n",
    "        return 'ARD'\n",
    "    if name == 9.0:\n",
    "        return 'Forest'\n",
    "\n",
    "\n",
    "#modelos\n",
    "modelos=np.array([[np.ones(len(test_rmse_scores_lin_reg))], [np.ones(len(test_rmse_scores_ridgeReg))*2], \n",
    "                  [np.ones(len(test_rmse_scores_Lassog))*3],[np.ones(len(test_rmse_scores_Elastic))*4],\n",
    "                  [np.ones(len(test_rmse_scores_KernelRidg))*5],[np.ones(len(test_rmse_scores_KernelRidge_l))*6],\n",
    "                  [np.ones(len(test_rmse_scores_ARD))*7],[np.ones(len(test_rmse_scores_ARD))*8],\n",
    "                  [np.ones(len(test_rmse_scores_forest_reg))*9]\n",
    "                 ])\n",
    "\n",
    "modelos=np.reshape(modelos,45)\n",
    "parametros_modelos=np.array([[test_rmse_scores_lin_reg], [test_rmse_scores_ridgeReg], \n",
    "                             [test_rmse_scores_Lassog], [test_rmse_scores_Elastic],\n",
    "                             [test_rmse_scores_KernelRidg],[test_rmse_scores_KernelRidge_l],\n",
    "                             [test_rmse_BayesianRidge],[test_rmse_scores_ARD],\n",
    "                             [test_rmse_scores_forest_reg]\n",
    "                            ])\n",
    "parametros_modelos=np.reshape(parametros_modelos, 45)\n",
    "\n",
    "rultados_de_test_train= {'modelos': pd.Series(modelos),                         \n",
    "                         'parametros_modelos': pd.Series(parametros_modelos)}\n",
    "                                                         \n",
    "\n",
    "rultados_de_test_train_table = pd.DataFrame(rultados_de_test_train)\n",
    "rultados_de_test_train_table['modelos']= rultados_de_test_train_table['modelos'].apply(lambda x:  modelos_name(x) )\n",
    "\n",
    "plt.figure(figsize=(25,10))\n",
    "sns.boxenplot(rultados_de_test_train_table['modelos'],rultados_de_test_train_table['parametros_modelos'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El intervalo de confianza al 95% se puede calcular para el RMSE sobre el conjunto de test:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could compute the interval manually like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Material extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline completo para preparación de datos y predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline_with_predictor = Pipeline([\n",
    "        (\"preparation\", full_pipeline),\n",
    "        (\"linear\", LinearRegression())\n",
    "    ])\n",
    "\n",
    "full_pipeline_with_predictor.fit(housing, housing_labels)\n",
    "full_pipeline_with_predictor.predict(some_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de modelo eficiente con joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = full_pipeline_with_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib #https://joblib.readthedocs.io/en/latest/\n",
    "joblib.dump(my_model, \"my_model.pkl\") # DIFF  https://docs.python.org/2/library/pickle.html\n",
    "#...\n",
    "my_model_loaded = joblib.load(\"my_model.pkl\") # DIFF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos de distribuciones en SciPy para `RandomizedSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import geom, expon\n",
    "geom_distrib=geom(0.5).rvs(10000, random_state=42)\n",
    "expon_distrib=expon(scale=1).rvs(10000, random_state=42)\n",
    "plt.hist(geom_distrib, bins=50)\n",
    "plt.show()\n",
    "plt.hist(expon_distrib, bins=50)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
